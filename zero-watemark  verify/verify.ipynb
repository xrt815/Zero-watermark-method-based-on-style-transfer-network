{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa74bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "\n",
    "import torchvision.utils as utils\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "import copy\n",
    "import glob\n",
    "import torch.utils.data as udata\n",
    "import h5py\n",
    "import cv2\n",
    "import random\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "from skimage.measure.simple_metrics import compare_psnr\n",
    "import scipy.io as sio\n",
    "import random\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b83116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#本代码，直接将风格合成结果输入残差网络，直接以原图和西电图之间的均方差作为损失，得到西电图\n",
    "opts = argparse.Namespace()\n",
    "opts.image_channel = 3 #为什么通道是6\n",
    "opts.batch_size = 4\n",
    "opts.lr = 1e-3\n",
    "opts.target_path = 'l2.png' #目标图 \n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    device = \"cuda:0\" \n",
    "    dtype = torch.cuda.FloatTensor \n",
    "    imsize = 128 \n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    dtype = torch.FloatTensor\n",
    "    # desired size of the output image\n",
    "    imsize = 128  # use small size if no gpu\n",
    "print(use_cuda)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4d5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = transforms.Compose([\n",
    "    transforms.Resize([imsize, imsize]),  # scale imported image\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = Variable(loader(image))\n",
    "    # fake batch dimension required to fit network's input dimensions\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "unloader = transforms.ToPILImage()  # reconvert into PIL image\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.clone().cpu()  # we clone the tensor to not do changes on it\n",
    "    image = image.view(3, imsize, imsize)  # remove the fake batch dimension\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) # pause a bit so that plots are updated\n",
    "    \n",
    "def image_unloader(tensor):\n",
    "    image = tensor.clone().cpu()  # we clone the tensor to not do changes on it\n",
    "    image = image.view(3, imsize, imsize)  # remove the fake batch dimension\n",
    "    image = unloader(image)\n",
    "    return image\n",
    "\n",
    "def pil2tensor(pil_img):\n",
    "    image = Variable(loader(pil_img))\n",
    "    # fake batch dimension required to fit network's input dimensions\n",
    "    image = image.unsqueeze(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f74f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sio.loadmat('ver') #加载数据库\n",
    "x = mat['img'] #图片\n",
    "x_name = mat['img_name'].squeeze() #图片名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c861c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3x3 convolution  网络部分 终于要看了\n",
    "#残差网络\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet\n",
    "class DenoiseNet2(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super(DenoiseNet2, self).__init__()\n",
    "        self.e1 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )# 64,32,32\n",
    "        self.e2 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )# 128,32,32\n",
    "        self.l1 = self.make_block(block, 128, 128)\n",
    "        self.l2 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(128, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )# 64,32,32\n",
    "        self.l3 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(128 + 64, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )# 64,32,32\n",
    "        self.l4 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(128 + 64 + 64, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )# 64,32,32\n",
    "        self.l5 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(128 + 64 + 64 + 64, 64, 1, 1, 0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )# 1, 128, 128\n",
    "        self.l6 = self.make_block(block, 128 + 64, 128 + 64)\n",
    "        self.l7 = self.make_block(block, 128 + 64, 128 + 64)\n",
    "        self.l8 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(128 + 64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )# 64,32,32\n",
    "        self.l9 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128 + 128, 64, 3, 2 , 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )# 64, 64, 64\n",
    "        self.l10 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(64, 3, 1, 1, 0),\n",
    "            nn.Sigmoid()\n",
    "        )# 1, 64, 64\n",
    "    \n",
    "    def make_block(self, block, in_c, out_c):\n",
    "        layers = []\n",
    "        layers.append(block(in_c, out_c, 1, False))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(e1)\n",
    "        l1 = self.l1(e2)\n",
    "        l2 = self.l2(l1)\n",
    "        in_l3 = torch.cat((l1, l2), dim = 1)\n",
    "        l3 = self.l3(in_l3)\n",
    "        in_l4 = torch.cat((l1, l2, l3), dim = 1)\n",
    "        l4 = self.l4(in_l4)\n",
    "        in_l5 = torch.cat((l1, l2, l3, l4), dim = 1)\n",
    "        l5 = self.l5(in_l5)\n",
    "        in_l6 = torch.cat((l1, l5), dim = 1)\n",
    "        l6 = self.l6(in_l6)\n",
    "        l7 = self.l7(l6)\n",
    "        l8 = self.l8(l7)\n",
    "        in_l9 = torch.cat((e2, l8), dim = 1)\n",
    "        l9 = self.l9(in_l9)\n",
    "        l10 = self.l10(l9)\n",
    "        return l10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "699dea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = DenoiseNet2(ResidualBlock).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2016b959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('extract_l2_1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6b1259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = 'style' #资源，保存的是全部风格图\n",
    "save_path = './verify/zero-watermark' #训练输入图片 攻击后合成图\n",
    "save_res_path = './verify/res' #输出结果  全部提取结果\n",
    "save_source_path = './verify/use_source' #训练合成资源\n",
    "dataset = x\n",
    "dataset_name = x_name\n",
    "for i in range(dataset.shape[0]):\n",
    "    msave_path = os.path.join(save_path, dataset_name[i].strip())\n",
    "    msave_res_path = os.path.join(save_res_path, dataset_name[i].strip())\n",
    "    msave_source_path = os.path.join(save_source_path, dataset_name[i].strip())\n",
    "    x = torch.tensor(dataset[i]).clone().unsqueeze(0)\n",
    "    x = x.to(device)\n",
    "    pred = net(x)\n",
    "    x = image_unloader(x)\n",
    "    x.save(msave_path) #攻击后合成图\n",
    "    pred = image_unloader(pred)\n",
    "    pred.save(msave_res_path) #提取结果\n",
    "    source = image_loader(os.path.join(source_path, dataset_name[i].strip()))\n",
    "    source = image_unloader(source)\n",
    "    source.save(msave_source_path) #我觉得有点不对劲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f3b6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_PATH = './st_test'\n",
    "# # SAVE_PATH = './res'\n",
    "# # source_path = 'res1' #资源，保存的是全部风格图\n",
    "# # save_path = './test1' #训练输入图片 攻击后合成图\n",
    "# # save_res_path = './test_res1' #输出结果  全部提取结果\n",
    "# # save_source_path = './test_source1' #训练合成资源\n",
    "\n",
    "# image_pathes = os.listdir(IMAGE_PATH)\n",
    "# images = []\n",
    "# for img_path in image_pathes:\n",
    "#     if os.path.isdir(img_path):\n",
    "#         continue\n",
    "#     tmp = image_loader(os.path.join(IMAGE_PATH,img_path)).detach().to(device)\n",
    "#     pred = net(tmp)\n",
    "#     print('_____________________________________')\n",
    "#     imshow(tmp,\"input\")\n",
    "#     imshow(pred,\"output\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
