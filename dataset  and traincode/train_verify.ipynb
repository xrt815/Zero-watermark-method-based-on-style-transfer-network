{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "\n",
    "import torchvision.utils as utils\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "import copy\n",
    "import glob\n",
    "import torch.utils.data as udata\n",
    "import h5py\n",
    "import cv2\n",
    "import random\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "from skimage.measure.simple_metrics import compare_psnr\n",
    "import scipy.io as sio\n",
    "import random\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#本代码，直接将风格合成结果输入残差网络，直接以原图和西电图之间的均方差作为损失，得到西电图\n",
    "opts = argparse.Namespace()\n",
    "opts.image_channel = 3 #为什么通道是6\n",
    "opts.batch_size = 3\n",
    "opts.lr = 1e-3\n",
    "opts.target_path = './content/l2.png' #目标图 就是西电内容图\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    device = \"cuda:0\" \n",
    "    dtype = torch.cuda.FloatTensor \n",
    "    imsize = 128 \n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    dtype = torch.FloatTensor\n",
    "    # desired size of the output image\n",
    "    imsize = 128  # use small size if no gpu\n",
    "print(use_cuda)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = transforms.Compose([\n",
    "    transforms.Resize([imsize, imsize]),  # scale imported image\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = Variable(loader(image))\n",
    "    # fake batch dimension required to fit network's input dimensions\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "unloader = transforms.ToPILImage()  # reconvert into PIL image\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.clone().cpu()  # we clone the tensor to not do changes on it\n",
    "    image = image.view(3, imsize, imsize)  # remove the fake batch dimension\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) # pause a bit so that plots are updated\n",
    "    \n",
    "def image_unloader(tensor):\n",
    "    image = tensor.clone().cpu()  # we clone the tensor to not do changes on it\n",
    "    image = image.view(3, imsize, imsize)  # remove the fake batch dimension\n",
    "    image = unloader(image)\n",
    "    return image\n",
    "\n",
    "def pil2tensor(pil_img):\n",
    "    image = Variable(loader(pil_img))\n",
    "    # fake batch dimension required to fit network's input dimensions\n",
    "    image = image.unsqueeze(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load content 加载内容图\n",
    "content_img = image_loader(opts.target_path).type(dtype) #.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sio.loadmat('l2_1') #加载数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mat['img'] #图片\n",
    "x_name = mat['img_name'].squeeze() #图片名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray(list(range(x.shape[0])))  #应该是数据集数量\n",
    "size = int(x.shape[0] * 0.8) #size = c*0.8?\n",
    "p1 = np.asarray(np.random.choice(a=a, size=size, replace=False)) #从中随机抽取百分之八十的数据作为训练集？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = []\n",
    "for tmp in a:\n",
    "    if(tmp not in p1):\n",
    "        p2.append(tmp)\n",
    "p2 = np.asarray(p2) #剩下的是测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.sort() #排序？意义在哪\n",
    "p2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x[p1]\n",
    "train_x_name = x_name[p1]\n",
    "test_x = x[p2]\n",
    "test_x_name = x_name[p2]\n",
    "target = image_loader(opts.target_path).to('cpu').detach().numpy()\n",
    "targets = [target for i in range(len(train_x))]\n",
    "targets = np.asarray(targets).squeeze(1)\n",
    "train_x = torch.from_numpy(train_x).type(dtype)\n",
    "train_y = torch.from_numpy(targets).type(dtype)\n",
    "test_x = torch.from_numpy(test_x).type(dtype)\n",
    "#[5-10]加载数据集，并随机划分数据为0.8的训练和0.2的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_x,train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=opts.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(test_x)\n",
    "test_loader = DataLoader(test_dataset, batch_size=opts.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3x3 convolution  网络部分 终于要看了\n",
    "#残差网络\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet\n",
    "class DenoiseNet2(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super(DenoiseNet2, self).__init__()\n",
    "        self.e1 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )# 64,32,32\n",
    "        self.e2 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )# 128,32,32\n",
    "        self.l1 = self.make_block(block, 128, 128)\n",
    "        self.l2 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(128, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )# 64,32,32\n",
    "        self.l3 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(128 + 64, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )# 64,32,32\n",
    "        self.l4 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(128 + 64 + 64, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )# 64,32,32\n",
    "        self.l5 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(128 + 64 + 64 + 64, 64, 1, 1, 0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )# 1, 128, 128\n",
    "        self.l6 = self.make_block(block, 128 + 64, 128 + 64)\n",
    "        self.l7 = self.make_block(block, 128 + 64, 128 + 64)\n",
    "        self.l8 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(128 + 64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )# 64,32,32\n",
    "        self.l9 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128 + 128, 64, 3, 2 , 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )# 64, 64, 64\n",
    "        self.l10 = nn.Sequential(\n",
    "            # param [input_c, output_c, kernel_size, stride, padding]\n",
    "            nn.Conv2d(64, 3, 1, 1, 0),\n",
    "            nn.Sigmoid()\n",
    "        )# 1, 64, 64\n",
    "    \n",
    "    def make_block(self, block, in_c, out_c):\n",
    "        layers = []\n",
    "        layers.append(block(in_c, out_c, 1, False))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(e1)\n",
    "        l1 = self.l1(e2)\n",
    "        l2 = self.l2(l1)\n",
    "        in_l3 = torch.cat((l1, l2), dim = 1)\n",
    "        l3 = self.l3(in_l3)\n",
    "        in_l4 = torch.cat((l1, l2, l3), dim = 1)\n",
    "        l4 = self.l4(in_l4)\n",
    "        in_l5 = torch.cat((l1, l2, l3, l4), dim = 1)\n",
    "        l5 = self.l5(in_l5)\n",
    "        in_l6 = torch.cat((l1, l5), dim = 1)\n",
    "        l6 = self.l6(in_l6)\n",
    "        l7 = self.l7(l6)\n",
    "        l8 = self.l8(l7)\n",
    "        in_l9 = torch.cat((e2, l8), dim = 1)\n",
    "        l9 = self.l9(in_l9)\n",
    "        l10 = self.l10(l9)\n",
    "        return l10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DenoiseNet2(ResidualBlock).to(device) #不知道为啥一直要.to （device）可以仔细看看，使用训练要求什么，把所有数据.to(device)?\n",
    "optimizer = optim.Adam(net.parameters(), lr=opts.lr) #Adam优化器\n",
    "criterion = nn.MSELoss() #损失使用MSE损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss: 0.01215791\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    train_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        x,y = data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = net(x)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(pred, y) #优化网络，使得输入风格合成图，输出能是那啥，内容\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    print('[Epoch %d] loss: %.8f' % (epoch + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型\n",
    "torch.save(net.state_dict(),'extract_l2_1.pth')\n",
    "# 加载模型\n",
    "net.load_state_dict(torch.load('extract_l2_1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = 'style_attack' #资源，保存的是全部风格图\n",
    "save_path = './extract_l2/train' #训练输入图片 攻击后合成图 从数据集就自己提取\n",
    "save_res_path = './extract_l2/train_res' #输出结果  全部提取结果 结果,由网络生成\n",
    "save_source_path = './extract_l2/train_source' #训练合成资源 对应资源从第一行位置获取\n",
    "dataset = train_x\n",
    "dataset_name = train_x_name\n",
    "for i in range(dataset.shape[0]):\n",
    "    msave_path = os.path.join(save_path, dataset_name[i].strip())\n",
    "    msave_res_path = os.path.join(save_res_path, dataset_name[i].strip())\n",
    "    msave_source_path = os.path.join(save_source_path, dataset_name[i].strip())\n",
    "    x = dataset[i].clone().unsqueeze(0)\n",
    "    x = x.to(device)\n",
    "    pred = net(x)\n",
    "    x = image_unloader(x)\n",
    "    x.save(msave_path) #攻击后合成图\n",
    "    pred = image_unloader(pred)\n",
    "    pred.save(msave_res_path) #提取结果\n",
    "    source = image_loader(os.path.join(source_path, dataset_name[i].strip()))\n",
    "    source = image_unloader(source)\n",
    "    source.save(msave_source_path) #我觉得有点不对劲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst = os.listdir('train_source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "source_path = 'style_attack' #资源，保存的是全部风格图\n",
    "save_path = './extract_l2/test' #训练输入图片 攻击后合成图\n",
    "save_res_path = './extract_l2/test_res' #输出结果  全部提取结果\n",
    "save_source_path = './extract_l2/test_source' #训练合成资源\n",
    "dataset = test_x\n",
    "dataset_name = test_x_name\n",
    "for i in range(dataset.shape[0]):\n",
    "    msave_path = os.path.join(save_path, dataset_name[i].strip())\n",
    "    msave_res_path = os.path.join(save_res_path, dataset_name[i].strip())\n",
    "    msave_source_path = os.path.join(save_source_path, dataset_name[i].strip())\n",
    "    x = dataset[i].clone().unsqueeze(0)\n",
    "    x = x.to(device)\n",
    "    pred = net(x)\n",
    "    x = image_unloader(x)\n",
    "    x.save(msave_path) #攻击后合成图\n",
    "    pred = image_unloader(pred)\n",
    "    pred.save(msave_res_path) #提取结果\n",
    "    source = image_loader(os.path.join(source_path, dataset_name[i].strip()))\n",
    "    source = image_unloader(source)\n",
    "    source.save(msave_source_path) #我觉得有点不对劲\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_PATH = './st_test'\n",
    "# # SAVE_PATH = './res'\n",
    "# # source_path = 'res1' #资源，保存的是全部风格图\n",
    "# # save_path = './test1' #训练输入图片 攻击后合成图\n",
    "# # save_res_path = './test_res1' #输出结果  全部提取结果\n",
    "# # save_source_path = './test_source1' #训练合成资源\n",
    "\n",
    "# image_pathes = os.listdir(IMAGE_PATH)\n",
    "# images = []\n",
    "# for img_path in image_pathes:\n",
    "#     if os.path.isdir(img_path):\n",
    "#         continue\n",
    "#     tmp = image_loader(os.path.join(IMAGE_PATH,img_path)).detach().to(device)\n",
    "#     pred = net(tmp)\n",
    "#     print('_____________________________________')\n",
    "#     imshow(tmp,\"input\")\n",
    "#     imshow(pred,\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
